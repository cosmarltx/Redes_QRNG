{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee489d4",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799eabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "largo_generacion = 5000000 \n",
    "bits = 4\n",
    "prob_bin = 1/(2 ** bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af553c",
   "metadata": {},
   "source": [
    "# Data cruda\n",
    "Se crea el arreglo de muestras partiendo del archivo data_4bits.txt que contiene 5000000 de datos crudos del QRNG en formato de 4 bits que siguen una distribución uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras = np.zeros(5000000, dtype = 'int8')\n",
    "\n",
    "f = open(\"data_4bits.txt\", \"r\")\n",
    "cadena = f.read()\n",
    "\n",
    "temp = ''\n",
    "contador = 0\n",
    "\n",
    "for a in cadena:\n",
    "    if a != \",\":\n",
    "        temp += a\n",
    "    else:\n",
    "        muestras[contador] = int(temp)\n",
    "        temp = ''\n",
    "        contador += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a5c3d",
   "metadata": {},
   "source": [
    "Se construye el histograma de probabilidad correspondiente a la distribución uniforme de 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e127e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = np.zeros(2 ** bits)\n",
    "\n",
    "for i in range(0, len(probabilidades)):\n",
    "    prob = np.count_nonzero(muestras == i)/len(muestras)\n",
    "    probabilidades[i] = prob\n",
    "\n",
    "nums_4bits = np.linspace(0,15,16)\n",
    "\n",
    "plt.bar(nums_4bits, probabilidades, color = 'blue')\n",
    "plt.axhline(prob_bin, color = 'red', label = 'y = ' + str(prob_bin))\n",
    "plt.xlabel('Número de 4 bits')\n",
    "plt.ylabel('Probabilidad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f35c69",
   "metadata": {},
   "source": [
    "# Conjuntos de ML\n",
    "Se construyen los conjuntos de entrenamiento y prueba o test. Como input, se utilizan secuencias cuya longitud es dada por la variable \"longitud_input\". El corrimiento es dado por \"Salto\". La variable \"porcentaje\" determina qué fracción de la muestra será para entrenar y cuanto se utilizará para el test final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud_input = 25\n",
    "Salto = 1\n",
    "porcentaje = 0.50\n",
    "\n",
    "longitud_entrenamiento = int(porcentaje * largo_generacion / Salto)\n",
    "longitud_test = int((1 - porcentaje) * largo_generacion / Salto - (longitud_input + 1))\n",
    "\n",
    "inputs_entrenamiento = np.zeros((longitud_entrenamiento, longitud_input), dtype = 'int8')\n",
    "outputs_entrenamiento = np.zeros((longitud_entrenamiento, 2 ** bits), dtype = 'int8')\n",
    "\n",
    "inputs_test = np.zeros((longitud_test, longitud_input), dtype = 'int8')\n",
    "outputs_test = np.zeros((longitud_test, 2 ** bits), dtype = 'int8')\n",
    "\n",
    "for i in range(0,longitud_entrenamiento):\n",
    "    inputs_entrenamiento[i] = muestras[i*Salto:i*Salto + longitud_input]\n",
    "    outputs_entrenamiento[i, muestras[i*Salto + longitud_input]] = 1\n",
    "    \n",
    "for i in range(longitud_entrenamiento,longitud_entrenamiento + longitud_test):\n",
    "    inputs_test[i - longitud_entrenamiento] = muestras[i*Salto:i*Salto + longitud_input]\n",
    "    outputs_test[i - longitud_entrenamiento, muestras[i*Salto + longitud_input]] = 1\n",
    "    \n",
    "inputs_entrenamiento = inputs_entrenamiento/(2**bits)\n",
    "inputs_test = inputs_test/(2**bits)\n",
    "\n",
    "print(inputs_entrenamiento.shape)\n",
    "print(outputs_entrenamiento.shape)\n",
    "print(inputs_test.shape)\n",
    "print(outputs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a48e41",
   "metadata": {},
   "source": [
    "# Modelo de red prealimentada (FNN)\n",
    "Se construye el modelo de red con keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_shape = (longitud_input,)\n",
    "activacion_oculta = 'relu'\n",
    "activacion_output = 'softmax'\n",
    "\n",
    "FNN = Sequential()\n",
    "\n",
    "FNN.add(Flatten(input_shape = input_data_shape, name = 'capa_inputs'))\n",
    "FNN.add(Dense(units = 64, activation = activacion_oculta))\n",
    "FNN.add(BatchNormalization())\n",
    "FNN.add(Dropout(0.2))\n",
    "FNN.add(Dense(units = 64, activation = activacion_oculta))\n",
    "FNN.add(BatchNormalization())\n",
    "FNN.add(Dropout(0.2))\n",
    "FNN.add(Dense(units = 16, activation = activacion_output))\n",
    "\n",
    "FNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e84cf0",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "Se entrena el modelo de machine learning con el conjunto de entrenamiento. Algunos hiperparámetros como la tasa de entrenamiento y el número de epochs se establecen al principio de la celda. La función de costo es \"categorical_crossentropy\". Adicionalmente, se utiliza un 10% de la data de entrenamiento como data de validación.\n",
    "\n",
    "Cabe mencionar que se aplica un EarlyStopping, el cual detiene el entrenamiento cuando el costo de validación no mejora en 10 epochs consecutivos. Al final del entrenamiento, se guarda la red con los parámetros que minimizaron el costo de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6eb611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tasa_entrenamiento = 0.0005\n",
    "numero_epochs = 50\n",
    "tamanio_minilote = 1024\n",
    "\n",
    "optimizador = Adam(learning_rate = tasa_entrenamiento)\n",
    "funcion_costo = 'categorical_crossentropy'\n",
    "metrica = ['accuracy']\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights=True)\n",
    "\n",
    "FNN.compile(optimizer = optimizador, loss = funcion_costo, metrics = metrica)\n",
    "entrenamiento = FNN.fit(inputs_entrenamiento, outputs_entrenamiento, batch_size = tamanio_minilote,\n",
    "                        callbacks = [callback], validation_split= 0.1, epochs = numero_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a7090",
   "metadata": {},
   "source": [
    "# Gráficas\n",
    "Se observa la evolución de la red a través de gráficas de costo y precisión tanto sobre el conjunto de entrenamiento como el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(entrenamiento.history['accuracy'], label = 'Entrenamiento')\n",
    "plt.plot(entrenamiento.history['val_accuracy'], label = 'Validación')\n",
    "plt.axhline(prob_bin, color = 'red', label = 'y = ' + str(prob_bin))\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entrenamiento.history['loss'], label = 'Entrenamiento')\n",
    "plt.plot(entrenamiento.history['val_loss'], label = 'Validación')\n",
    "plt.ylabel('Costo')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67923b8",
   "metadata": {},
   "source": [
    "# Evaluación\n",
    "Se evalúa la red mediante el conjunto de prueba o test para observar si el modelo pudo generalizarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "costo_test, precision_test = FNN.evaluate(inputs_test, outputs_test)\n",
    "\n",
    "print(\"El costo sobre el conjunto de prueba es: \" + str(costo_test))\n",
    "print(\"La precisión sobre el conjunto de prueba es: \" + str(precision_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6661931",
   "metadata": {},
   "source": [
    "# Prueba estadística\n",
    "A continuación se preparan los datos necesarios para la prueba estadística. Primero se constuye el arreglo mtp de datos crudos que serán sometidos a los métodos de predicción A y B. El método A es la red neuronal, mientras que el método B consiste en adivinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71472e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp = np.zeros(2500000, dtype = 'int8')\n",
    "\n",
    "f = open(\"prueba_estadistica.txt\", \"r\")\n",
    "cadena = f.read()\n",
    "\n",
    "temp = ''\n",
    "contador = 0\n",
    "\n",
    "for a in cadena:\n",
    "    if a != \",\":\n",
    "        temp += a\n",
    "    else:\n",
    "        mtp[contador] = int(temp)\n",
    "        temp = ''\n",
    "        contador += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f46d5",
   "metadata": {},
   "source": [
    "A partir de mtp se crean 500 subconjuntos. Todos cuentan con 4000 muestras. Se observa cuantos aciertos se logran en cada subconjunto empleando los métodos A y B descritos anteriormente. Por lo tanto, al terminar se tendrán 500 datos emparejados sobre el desempeño de los métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tamanio_subconjunto = 4000\n",
    "numero_subconjuntos = 500\n",
    "\n",
    "muestra_A = np.zeros(numero_subconjuntos)\n",
    "muestra_B = np.zeros(numero_subconjuntos)\n",
    "\n",
    "longitud_input = 25\n",
    "\n",
    "for i in tqdm(range(0, numero_subconjuntos)):\n",
    "    inputs_estadistico = np.zeros((tamanio_subconjunto, longitud_input), dtype = 'int8')\n",
    "    outputs_estadistico_mA = np.zeros((tamanio_subconjunto, 2 ** bits), dtype = 'int8')\n",
    "    outputs_estadistico_mB = np.zeros(tamanio_subconjunto, dtype = 'int8')\n",
    "    \n",
    "    for j in range(0,tamanio_subconjunto):\n",
    "        inputs_estadistico[j] = mtp[j + i * tamanio_subconjunto:j + i * tamanio_subconjunto + longitud_input]\n",
    "        outputs_estadistico_mA[j, mtp[j + i * tamanio_subconjunto + longitud_input]] = 1\n",
    "        outputs_estadistico_mB[j] = mtp[j + i * tamanio_subconjunto + longitud_input]\n",
    "     \n",
    "    inputs_estadistico = inputs_estadistico/(2 ** bits)\n",
    "    \n",
    "    #prueba red neuronal\n",
    "    costo_estadistico, precision_estadistico = FNN.evaluate(inputs_estadistico, outputs_estadistico_mA, verbose = 0)\n",
    "    aciertos_mA = round(precision_estadistico * tamanio_subconjunto)\n",
    "    \n",
    "    #prueba adivinar aleatoriamente\n",
    "    aciertos_mB = 0\n",
    "    for k in range(0,tamanio_subconjunto):\n",
    "        guess = rd.randint(0,15)\n",
    "        \n",
    "        if guess == outputs_estadistico_mB[k]:\n",
    "            aciertos_mB += 1\n",
    "    \n",
    "    muestra_A[i] = aciertos_mA\n",
    "    muestra_B[i] = aciertos_mB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752a33b",
   "metadata": {},
   "source": [
    "Finalmente, los datos emparejados se exportan a Excel donde se realiza la prueba estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8666ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "df = pd.DataFrame(list(zip(muestra_A, muestra_B)), columns=['Aciertos NN', 'Aciertos Adivinando'])\n",
    "print(df)\n",
    "\n",
    "df.to_excel('prueba_estadistica_FNN.xlsx', sheet_name='FNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
