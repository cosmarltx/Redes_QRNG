{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee489d4",
   "metadata": {
    "id": "6ee489d4"
   },
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27e5d3",
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1680125404507,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "2d27e5d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Dropout,BatchNormalization,LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799eabaf",
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1680125407094,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "799eabaf"
   },
   "outputs": [],
   "source": [
    "largo_generacion = 5000000 \n",
    "bits = 4\n",
    "prob_bin = 1/(2 ** bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af553c",
   "metadata": {
    "id": "b5af553c"
   },
   "source": [
    "# Data cruda\n",
    "Se crea el arreglo de muestras partiendo del archivo data_4bits.txt que contiene 5000000 de datos crudos del QRNG en formato de 4 bits que siguen una distribución uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0a307",
   "metadata": {
    "executionInfo": {
     "elapsed": 2714,
     "status": "ok",
     "timestamp": 1680125491651,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "75a0a307"
   },
   "outputs": [],
   "source": [
    "muestras = np.zeros(5000000, dtype = 'int8')\n",
    "\n",
    "f = open(\"data_4bits.txt\", \"r\")\n",
    "cadena = f.read()\n",
    "\n",
    "temp = ''\n",
    "contador = 0\n",
    "\n",
    "for a in cadena:\n",
    "    if a != \",\":\n",
    "        temp += a\n",
    "    else:\n",
    "        muestras[contador] = int(temp)\n",
    "        temp = ''\n",
    "        contador += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a5c3d",
   "metadata": {
    "id": "868a5c3d"
   },
   "source": [
    "Se construye el histograma de probabilidad correspondiente a la distribución uniforme de 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e127e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1680125494541,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "36e127e2",
    "outputId": "b3c6e56d-cf58-460b-9fb8-fb547bd7947b"
   },
   "outputs": [],
   "source": [
    "probabilidades = np.zeros(2 ** bits)\n",
    "\n",
    "for i in range(0, len(probabilidades)):\n",
    "    prob = np.count_nonzero(muestras == i)/len(muestras)\n",
    "    probabilidades[i] = prob\n",
    "\n",
    "nums_4bits = np.linspace(0,15,16)\n",
    "\n",
    "plt.bar(nums_4bits, probabilidades, color = 'blue')\n",
    "plt.axhline(prob_bin, color = 'red', label = 'y = ' + str(prob_bin))\n",
    "plt.xlabel('Número de 4 bits')\n",
    "plt.ylabel('Probabilidad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f35c69",
   "metadata": {
    "id": "a6f35c69"
   },
   "source": [
    "# Conjuntos de ML\n",
    "Se construyen los conjuntos de entrenamiento y prueba o test. Como input, se utilizan secuencias cuya longitud es dada por la variable \"longitud_input\". Dichas secuencias se codifican con vectores one-hot. Por otro lado, el corrimiento es dado por \"Salto\". La variable \"porcentaje\" determina qué fracción de la muestra será para entrenar y cuanto se utilizará para el test final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec8109",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76989,
     "status": "ok",
     "timestamp": 1680125670444,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "cfec8109",
    "outputId": "8b95ff9a-b15c-4336-b912-74020afd31ab"
   },
   "outputs": [],
   "source": [
    "longitud_input = 32\n",
    "Salto = 1\n",
    "porcentaje = 0.50\n",
    "\n",
    "longitud_entrenamiento = int(porcentaje * largo_generacion / Salto)\n",
    "longitud_test = int((1 - porcentaje) * largo_generacion / Salto - (longitud_input + 1))\n",
    "\n",
    "inputs_entrenamiento = np.zeros((longitud_entrenamiento, longitud_input, 2 ** bits), dtype = 'int8')\n",
    "outputs_entrenamiento = np.zeros((longitud_entrenamiento, 2 ** bits), dtype = 'int8')\n",
    "\n",
    "inputs_test = np.zeros((longitud_test, longitud_input, 2 ** bits), dtype = 'int8')\n",
    "outputs_test = np.zeros((longitud_test, 2 ** bits), dtype = 'int8')\n",
    "\n",
    "for i in range(0,longitud_entrenamiento):\n",
    "    for j in range(0, longitud_input):\n",
    "        inputs_entrenamiento[i,j,muestras[i * Salto + j]] = 1\n",
    "    \n",
    "    outputs_entrenamiento[i, muestras[i*Salto + longitud_input]] = 1\n",
    "    \n",
    "for i in range(longitud_entrenamiento,longitud_entrenamiento + longitud_test):\n",
    "    for j in range(0, longitud_input):\n",
    "        inputs_test[i - longitud_entrenamiento, j, muestras[i * Salto + j]] = 1\n",
    "    \n",
    "    outputs_test[i - longitud_entrenamiento, muestras[i*Salto + longitud_input]] = 1\n",
    "    \n",
    "print(inputs_entrenamiento.shape)\n",
    "print(outputs_entrenamiento.shape)\n",
    "print(inputs_test.shape)\n",
    "print(outputs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a48e41",
   "metadata": {
    "id": "d7a48e41"
   },
   "source": [
    "# Modelo de red recurrente con LSTM\n",
    "Se construye el modelo de red con keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca0d3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3490,
     "status": "ok",
     "timestamp": 1680125673930,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "d5ca0d3a",
    "outputId": "7bd53713-594d-40a2-8549-15de7f81be9c"
   },
   "outputs": [],
   "source": [
    "input_data_shape = (longitud_input, 2 ** bits)\n",
    "activacion_lstm = 'relu'\n",
    "activacion_oculta = 'relu'\n",
    "activacion_output = 'softmax'\n",
    "\n",
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(LSTM(units = 64, input_shape = input_data_shape, activation = activacion_lstm,\n",
    "              return_sequences = False, name = 'capa_lstm'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.1))\n",
    "lstm.add(Dense(units = 64, activation = activacion_oculta, name = 'capa_oculta'))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dropout(0.1))\n",
    "lstm.add(Dense(units = 2 ** bits, activation = activacion_output, name = 'capa_output'))\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e84cf0",
   "metadata": {
    "id": "d3e84cf0"
   },
   "source": [
    "# Entrenamiento\n",
    "Se entrena el modelo de machine learning con el conjunto de entrenamiento. Algunos hiperparámetros como la tasa de entrenamiento y el número de epochs se establecen al principio de la celda. La función de costo es \"categorical_crossentropy\". Adicionalmente, se utiliza un 10% de la data de entrenamiento como data de validación.\n",
    "\n",
    "Cabe mencionar que se aplica un EarlyStopping, el cual detiene el entrenamiento cuando el costo de validación no mejora en 10 epochs consecutivos. Al final del entrenamiento, se guarda la red con los parámetros que minimizaron el costo de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6eb611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2505635,
     "status": "ok",
     "timestamp": 1680128182113,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "fe6eb611",
    "outputId": "ab541c86-e067-455e-9f4d-fa772c699d11"
   },
   "outputs": [],
   "source": [
    "tasa_entrenamiento = 0.0005\n",
    "numero_epochs = 50\n",
    "tamanio_minilote = 1024\n",
    "\n",
    "optimizador = Adam(learning_rate = tasa_entrenamiento)\n",
    "funcion_costo = 'categorical_crossentropy'\n",
    "metrica = ['accuracy']\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights=True)\n",
    "\n",
    "lstm.compile(optimizer = optimizador, loss = funcion_costo, metrics = metrica)\n",
    "entrenamiento = lstm.fit(inputs_entrenamiento, outputs_entrenamiento, batch_size = tamanio_minilote,\n",
    "                         callbacks = [callback], validation_split= 0.1, epochs = numero_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a7090",
   "metadata": {
    "id": "ec5a7090"
   },
   "source": [
    "# Gráficas\n",
    "Se observa la evolución de la red a través de gráficas de costo y precisión tanto sobre el conjunto de entrenamiento como el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8545ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 56129,
     "status": "ok",
     "timestamp": 1679596065703,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "8a8545ad",
    "outputId": "e2be7bb5-84cd-4f27-fd32-0dc35f92f88d"
   },
   "outputs": [],
   "source": [
    "plt.plot(entrenamiento.history['accuracy'], label = 'Entrenamiento')\n",
    "plt.plot(entrenamiento.history['val_accuracy'], label = 'Validación')\n",
    "plt.axhline(prob_bin, color = 'red', label = 'y = ' + str(prob_bin))\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entrenamiento.history['loss'], label = 'Entrenamiento')\n",
    "plt.plot(entrenamiento.history['val_loss'], label = 'Validación')\n",
    "plt.ylabel('Costo')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67923b8",
   "metadata": {
    "id": "e67923b8"
   },
   "source": [
    "# Evaluación\n",
    "Se evalúa la red mediante el conjunto de prueba o test para observar si el modelo pudo generalizarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00729e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383214,
     "status": "ok",
     "timestamp": 1679596457581,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "9e00729e",
    "outputId": "d4275356-0ef2-42f5-8853-616018503883"
   },
   "outputs": [],
   "source": [
    "costo_test, precision_test = lstm.evaluate(inputs_test, outputs_test)\n",
    "\n",
    "print(\"El costo sobre el conjunto de prueba es: \" + str(costo_test))\n",
    "print(\"La precisión sobre el conjunto de prueba es: \" + str(precision_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25502379",
   "metadata": {},
   "source": [
    "# Prueba estadística\n",
    "A continuación se preparan los datos necesarios para la prueba estadística. Primero se constuye el arreglo mtp de datos crudos que serán sometidos a los métodos de predicción A y B. El método A es la red neuronal, mientras que el método B consiste en adivinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x4jlSlrMTLkx",
   "metadata": {
    "executionInfo": {
     "elapsed": 2110,
     "status": "ok",
     "timestamp": 1680128269106,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "x4jlSlrMTLkx"
   },
   "outputs": [],
   "source": [
    "mtp = np.zeros(2500000, dtype = 'int8')\n",
    "\n",
    "f = open(\"prueba_estadistica.txt\", \"r\")\n",
    "cadena = f.read()\n",
    "\n",
    "temp = ''\n",
    "contador = 0\n",
    "\n",
    "for a in cadena:\n",
    "    if a != \",\":\n",
    "        temp += a\n",
    "    else:\n",
    "        mtp[contador] = int(temp)\n",
    "        temp = ''\n",
    "        contador += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad364f",
   "metadata": {},
   "source": [
    "A partir de mtp se crean 500 subconjuntos. Todos cuentan con 4000 muestras. Se observa cuantos aciertos se logran en cada subconjunto empleando los métodos A y B descritos anteriormente. Por lo tanto, al terminar se tendrán 500 datos emparejados sobre el desempeño de los métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cYWRQjYGTVv8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545538,
     "status": "ok",
     "timestamp": 1680128822787,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "cYWRQjYGTVv8",
    "outputId": "3ba179ac-52e7-4912-e14a-55e5b0a40e1f"
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tamanio_subconjunto = 4000\n",
    "numero_subconjuntos = 500\n",
    "\n",
    "muestra_A = np.zeros(numero_subconjuntos)\n",
    "muestra_B = np.zeros(numero_subconjuntos)\n",
    "\n",
    "longitud_input = 32\n",
    "\n",
    "for i in tqdm(range(0, numero_subconjuntos)):\n",
    "    inputs_estadistico = np.zeros((tamanio_subconjunto, longitud_input, 2 ** bits), dtype = 'int8')\n",
    "    outputs_estadistico_mA = np.zeros((tamanio_subconjunto, 2 ** bits), dtype = 'int8')\n",
    "    outputs_estadistico_mB = np.zeros(tamanio_subconjunto, dtype = 'int8')\n",
    "    \n",
    "    for j in range(0,tamanio_subconjunto):\n",
    "        for m in range(0, longitud_input):\n",
    "            inputs_estadistico[j,m,mtp[j + i * tamanio_subconjunto + m]] = 1\n",
    "\n",
    "        outputs_estadistico_mA[j, mtp[j + i * tamanio_subconjunto + longitud_input]] = 1\n",
    "        outputs_estadistico_mB[j] = mtp[j + i * tamanio_subconjunto + longitud_input]\n",
    "     \n",
    "    #prueba red neuronal\n",
    "    costo_estadistico, precision_estadistico = lstm.evaluate(inputs_estadistico, outputs_estadistico_mA, verbose = 0)\n",
    "    aciertos_mA = round(precision_estadistico * tamanio_subconjunto)\n",
    "    \n",
    "    #prueba adivinar aleatoriamente\n",
    "    aciertos_mB = 0\n",
    "    for k in range(0,tamanio_subconjunto):\n",
    "        guess = rd.randint(0,15)\n",
    "        \n",
    "        if guess == outputs_estadistico_mB[k]:\n",
    "            aciertos_mB += 1\n",
    "    \n",
    "    muestra_A[i] = aciertos_mA\n",
    "    muestra_B[i] = aciertos_mB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb9f07",
   "metadata": {},
   "source": [
    "Finalmente, los datos emparejados se exportan a Excel donde se realiza la prueba estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhzblQD6YOZF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1680128970879,
     "user": {
      "displayName": "JULIO MARCOS MONZON BALDETTI",
      "userId": "13304646209288137935"
     },
     "user_tz": 360
    },
    "id": "mhzblQD6YOZF",
    "outputId": "2fb4498b-6c67-4789-da50-d48daa35373c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "df = pd.DataFrame(list(zip(muestra_A, muestra_B)), columns=['Aciertos NN', 'Aciertos Adivinando'])\n",
    "print(df)\n",
    "\n",
    "df.to_excel('prueba_estadistica_LSTM.xlsx', sheet_name='LSTM')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
